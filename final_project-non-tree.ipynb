{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "#tf.get_logger().setLevel('ERROR') # turn off tf warnings \n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "\n",
       "    margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1  0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2  0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3  0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4  0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
       "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "3   0.000000   0.047852  \n",
       "4   0.000000   0.031250  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 194)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           990\n",
       "species       99\n",
       "margin1       46\n",
       "margin2       85\n",
       "margin3       66\n",
       "            ... \n",
       "texture60    102\n",
       "texture61     53\n",
       "texture62    127\n",
       "texture63     65\n",
       "texture64     97\n",
       "Length: 194, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique values \n",
    "train.nunique(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0.0\n",
       "species      0.0\n",
       "margin1      0.0\n",
       "margin2      0.0\n",
       "margin3      0.0\n",
       "            ... \n",
       "texture60    0.0\n",
       "texture61    0.0\n",
       "texture62    0.0\n",
       "texture63    0.0\n",
       "texture64    0.0\n",
       "Length: 194, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value percentage\n",
    "train.apply(lambda x: x.isnull().sum() / x.isnull().count()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['species'].value_counts().plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balanced class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.drop(['shape33', 'species'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "shape49  shape50    0.993873\n",
      "shape17  shape18    0.993863\n",
      "shape15  shape16    0.993723\n",
      "shape16  shape17    0.993606\n",
      "shape18  shape19    0.993604\n",
      "                      ...   \n",
      "shape50  shape53    0.951997\n",
      "shape19  shape49    0.951760\n",
      "shape14  shape49    0.951027\n",
      "shape10  shape13    0.950881\n",
      "shape11  shape45    0.950586\n",
      "Length: 190, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check Collinearity\n",
    "\n",
    "def get_redundant_pairs(train):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = train.columns\n",
    "    for i in range(0, train.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(train, n=5):\n",
    "    au_corr = train.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(train)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(train2, 190))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Field</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>Coefficient of Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>shape38</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>shape37</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>shape39</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>shape59</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>shape28</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>texture33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430660</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.058630</td>\n",
       "      <td>0.058630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>texture60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578130</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.060151</td>\n",
       "      <td>0.060151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>texture55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429690</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>0.063403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>texture15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853520</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.063881</td>\n",
       "      <td>0.063881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>texture12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507810</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.072506</td>\n",
       "      <td>0.072506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Field   minimum   maximum      mean       std  \\\n",
       "100       shape38  0.000064  0.002107  0.000621  0.000240   \n",
       "99        shape37  0.000067  0.002011  0.000642  0.000242   \n",
       "101       shape39  0.000062  0.002106  0.000602  0.000245   \n",
       "121       shape59  0.000063  0.001740  0.000607  0.000245   \n",
       "91        shape28  0.000087  0.001810  0.000644  0.000245   \n",
       "..            ...       ...       ...       ...       ...   \n",
       "159     texture33  0.000000  0.430660  0.023243  0.058630   \n",
       "186     texture60  0.000000  0.578130  0.014017  0.060151   \n",
       "181     texture55  0.000000  0.429690  0.036501  0.063403   \n",
       "141     texture15  0.000000  0.853520  0.012030  0.063881   \n",
       "138     texture12  0.000000  0.507810  0.026541  0.072506   \n",
       "\n",
       "     Coefficient of Variation  \n",
       "100                  0.000240  \n",
       "99                   0.000242  \n",
       "101                  0.000245  \n",
       "121                  0.000245  \n",
       "91                   0.000245  \n",
       "..                        ...  \n",
       "159                  0.058630  \n",
       "186                  0.060151  \n",
       "181                  0.063403  \n",
       "141                  0.063881  \n",
       "138                  0.072506  \n",
       "\n",
       "[189 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Coefficient of Variation\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for thisVar in train2.iloc[:,1:190].columns:\n",
    "    minimum = min(train2[thisVar])\n",
    "    maximum = max(train2[thisVar])\n",
    "    mean = np.mean(train2[thisVar])\n",
    "    std = np.std(train2[thisVar], ddof = 1)\n",
    "    coefVar = std / max(1.0, abs(mean))\n",
    "    if mean < 0:\n",
    "        coefVar = -coefVar\n",
    "  \n",
    "    result = result.append([[thisVar, minimum, maximum, mean, std, \\\n",
    "                            coefVar]],ignore_index = True)\n",
    "\n",
    "result = result.rename(columns= {0:'Feature Field', 1: 'minimum', \n",
    "                                 2: 'maximum', 3: 'mean',\n",
    "                                 4: 'std', 5 :'Coefficient of Variation'})\n",
    "result\n",
    "result.sort_values(by='Coefficient of Variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.053711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0   4  0.019531  0.009766  0.078125  0.011719  0.003906  0.015625  0.005859   \n",
       "1   7  0.007812  0.005859  0.064453  0.009766  0.003906  0.013672  0.007812   \n",
       "2   9  0.000000  0.000000  0.001953  0.021484  0.041016  0.000000  0.023438   \n",
       "3  12  0.000000  0.000000  0.009766  0.011719  0.017578  0.000000  0.003906   \n",
       "4  13  0.001953  0.000000  0.015625  0.009766  0.039062  0.000000  0.009766   \n",
       "\n",
       "   margin8   margin9  ...  texture55  texture56  texture57  texture58  \\\n",
       "0      0.0  0.005859  ...   0.006836   0.000000   0.015625   0.000977   \n",
       "1      0.0  0.033203  ...   0.000000   0.000000   0.006836   0.001953   \n",
       "2      0.0  0.011719  ...   0.128910   0.000000   0.000977   0.000000   \n",
       "3      0.0  0.003906  ...   0.012695   0.015625   0.002930   0.036133   \n",
       "4      0.0  0.005859  ...   0.000000   0.042969   0.016602   0.010742   \n",
       "\n",
       "   texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.015625        0.0        0.0   0.000000   0.003906   0.053711  \n",
       "1   0.013672        0.0        0.0   0.000977   0.037109   0.044922  \n",
       "2   0.000000        0.0        0.0   0.015625   0.000000   0.000000  \n",
       "3   0.013672        0.0        0.0   0.089844   0.000000   0.008789  \n",
       "4   0.041016        0.0        0.0   0.007812   0.009766   0.007812  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_id = train.pop('id')\n",
    "\n",
    "Y_label = train.pop('species')\n",
    "\n",
    "test_id = test.pop('id')\n",
    "\n",
    "X = train.values\n",
    "\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_testS = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training set to training and validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(random_state=233, test_size=0.2)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y_label = pd.Series(encoder.fit_transform(Y_label))\n",
    "\n",
    "#x_train, x_valid, y_train, y_valid\n",
    "train_ID, valid_ID = next(sss.split(X_scaled, y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_scaled[train_ID], y_label[train_ID]\n",
    "\n",
    "X_valid, y_valid = X_scaled[valid_ID], y_label[valid_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = Y_train_id.loc[y_train.index]\n",
    "train_species = Y_train.loc[y_train.index]\n",
    "\n",
    "valid_id = Y_train_id.loc[y_valid.index]\n",
    "valid_species = Y_train.loc[y_valid.index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      0.50      0.67         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       0.67      1.00      0.80         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       0.50      0.50      0.50         2\n",
      "          87       0.67      1.00      0.80         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       0.67      1.00      0.80         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.97       198\n",
      "   macro avg       0.97      0.97      0.97       198\n",
      "weighted avg       0.97      0.97      0.97       198\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "Accuracy of Random Forest classifier on test set: 97.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf1 = RandomForestClassifier(random_state=233, n_jobs=-1)\n",
    "clf1.fit(X_train, y_train)\n",
    "pred1 = clf1.predict(X_valid)\n",
    "confusion_matrix = confusion_matrix(y_valid, pred1)\n",
    "\n",
    "print(classification_report(y_true=y_valid, y_pred=pred1))\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of Random Forest classifier on test set: {:.2f}'.format(clf1.score(X_valid, y_valid)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.50      1.00      0.67         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      0.50      0.67         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.67      1.00      0.80         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      0.50      0.67         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       0.67      1.00      0.80         2\n",
      "          40       1.00      0.50      0.67         2\n",
      "          41       0.67      1.00      0.80         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       0.50      1.00      0.67         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      0.50      0.67         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       198\n",
      "   macro avg       0.97      0.96      0.96       198\n",
      "weighted avg       0.97      0.96      0.96       198\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "Accuracy of LDA classifier on testing set: 96.46\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda.fit(X_train,y_train)\n",
    "y_pred = model_lda.predict(X_valid)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of LDA classifier on testing set: {:.2f}'.format(model_lda.score(X_valid, y_valid)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.50      1.00      0.67         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      0.50      0.67         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.67      1.00      0.80         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      0.50      0.67         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       0.67      1.00      0.80         2\n",
      "          40       1.00      0.50      0.67         2\n",
      "          41       0.67      1.00      0.80         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       0.50      1.00      0.67         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      0.50      0.67         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       198\n",
      "   macro avg       0.97      0.96      0.96       198\n",
      "weighted avg       0.97      0.96      0.96       198\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "Accuracy of LDA classifier on training set: 100.00\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model_lda2 = LinearDiscriminantAnalysis()\n",
    "model_lda2.fit(X_train,y_train)\n",
    "y_pred2 = model_lda2.predict(X_train)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'.format(model_lda2.score(X_train, y_train)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.50      0.50      0.50         2\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      0.50      0.50         2\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.25      0.50      0.33         2\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         2\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.33      0.50      0.40         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.25      0.50      0.33         2\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         2\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       1.00      0.50      0.67         2\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         2\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         2\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.03       198\n",
      "   macro avg       0.03      0.03      0.03       198\n",
      "weighted avg       0.03      0.03      0.03       198\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy of QDA classifier on testing set: 3.03\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model_qda = QuadraticDiscriminantAnalysis()\n",
    "model_qda.fit(X_train,y_train)\n",
    "y_pred = model_qda.predict(X_valid)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of QDA classifier on testing set: {:.2f}'.format(model_qda.score(X_valid, y_valid)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         8\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      1.00      1.00         8\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       1.00      1.00      1.00         8\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      1.00      1.00         8\n",
      "          15       1.00      1.00      1.00         8\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         8\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00         8\n",
      "          24       1.00      1.00      1.00         8\n",
      "          25       1.00      1.00      1.00         8\n",
      "          26       1.00      1.00      1.00         8\n",
      "          27       1.00      1.00      1.00         8\n",
      "          28       1.00      1.00      1.00         8\n",
      "          29       1.00      1.00      1.00         8\n",
      "          30       1.00      1.00      1.00         8\n",
      "          31       1.00      1.00      1.00         8\n",
      "          32       1.00      1.00      1.00         8\n",
      "          33       1.00      1.00      1.00         8\n",
      "          34       1.00      1.00      1.00         8\n",
      "          35       1.00      1.00      1.00         8\n",
      "          36       1.00      1.00      1.00         8\n",
      "          37       1.00      1.00      1.00         8\n",
      "          38       1.00      1.00      1.00         8\n",
      "          39       1.00      1.00      1.00         8\n",
      "          40       1.00      1.00      1.00         8\n",
      "          41       1.00      1.00      1.00         8\n",
      "          42       1.00      1.00      1.00         8\n",
      "          43       1.00      1.00      1.00         8\n",
      "          44       1.00      1.00      1.00         8\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       1.00      1.00      1.00         8\n",
      "          47       1.00      1.00      1.00         8\n",
      "          48       1.00      1.00      1.00         8\n",
      "          49       1.00      1.00      1.00         8\n",
      "          50       1.00      1.00      1.00         8\n",
      "          51       1.00      1.00      1.00         8\n",
      "          52       1.00      1.00      1.00         8\n",
      "          53       1.00      1.00      1.00         8\n",
      "          54       1.00      1.00      1.00         8\n",
      "          55       1.00      1.00      1.00         8\n",
      "          56       1.00      1.00      1.00         8\n",
      "          57       1.00      1.00      1.00         8\n",
      "          58       1.00      1.00      1.00         8\n",
      "          59       1.00      1.00      1.00         8\n",
      "          60       1.00      1.00      1.00         8\n",
      "          61       1.00      1.00      1.00         8\n",
      "          62       1.00      1.00      1.00         8\n",
      "          63       1.00      1.00      1.00         8\n",
      "          64       1.00      1.00      1.00         8\n",
      "          65       1.00      1.00      1.00         8\n",
      "          66       1.00      1.00      1.00         8\n",
      "          67       1.00      1.00      1.00         8\n",
      "          68       1.00      1.00      1.00         8\n",
      "          69       1.00      1.00      1.00         8\n",
      "          70       1.00      1.00      1.00         8\n",
      "          71       1.00      1.00      1.00         8\n",
      "          72       1.00      1.00      1.00         8\n",
      "          73       1.00      1.00      1.00         8\n",
      "          74       1.00      1.00      1.00         8\n",
      "          75       1.00      1.00      1.00         8\n",
      "          76       1.00      1.00      1.00         8\n",
      "          77       1.00      1.00      1.00         8\n",
      "          78       1.00      1.00      1.00         8\n",
      "          79       1.00      1.00      1.00         8\n",
      "          80       1.00      1.00      1.00         8\n",
      "          81       1.00      1.00      1.00         8\n",
      "          82       1.00      1.00      1.00         8\n",
      "          83       1.00      1.00      1.00         8\n",
      "          84       1.00      1.00      1.00         8\n",
      "          85       1.00      1.00      1.00         8\n",
      "          86       1.00      1.00      1.00         8\n",
      "          87       1.00      1.00      1.00         8\n",
      "          88       1.00      1.00      1.00         8\n",
      "          89       1.00      1.00      1.00         8\n",
      "          90       1.00      1.00      1.00         8\n",
      "          91       1.00      1.00      1.00         8\n",
      "          92       1.00      1.00      1.00         8\n",
      "          93       1.00      1.00      1.00         8\n",
      "          94       1.00      1.00      1.00         8\n",
      "          95       1.00      1.00      1.00         8\n",
      "          96       1.00      1.00      1.00         8\n",
      "          97       1.00      1.00      1.00         8\n",
      "          98       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00       792\n",
      "   macro avg       1.00      1.00      1.00       792\n",
      "weighted avg       1.00      1.00      1.00       792\n",
      "\n",
      "<function confusion_matrix at 0x000002AEAA8D3550>\n",
      "Accuracy of QDA classifier on training set: 100.00\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model_qda2 = QuadraticDiscriminantAnalysis()\n",
    "model_qda2.fit(X_train,y_train)\n",
    "y_pred2 = model_qda2.predict(X_train)\n",
    "\n",
    "confusion_matrix2 = confusion_matrix(y_train, y_pred2)\n",
    "\n",
    "print(classification_report(y_train, y_pred2))\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of QDA classifier on training set: {:.2f}'.format(model_qda2.score(X_train, y_train)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       0.67      1.00      0.80         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      0.50      0.67         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.99       198\n",
      "   macro avg       1.00      0.99      0.99       198\n",
      "weighted avg       1.00      0.99      0.99       198\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "Accuracy of SVM classifier on testing set: 99.49\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "\n",
    "model_svm = svm.SVC(gamma=0.001, C=100.)\n",
    "model_svm.fit(X_train,y_train)\n",
    "y_pred = model_svm.predict(X_valid)\n",
    "\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "confusion_matrix = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(confusion_matrix)\n",
    "print('Accuracy of SVM classifier on testing set: {:.2f}'.format(model_svm.score(X_valid, y_valid)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         8\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      1.00      1.00         8\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       1.00      1.00      1.00         8\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      1.00      1.00         8\n",
      "          15       1.00      1.00      1.00         8\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         8\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00         8\n",
      "          24       1.00      1.00      1.00         8\n",
      "          25       1.00      1.00      1.00         8\n",
      "          26       1.00      1.00      1.00         8\n",
      "          27       1.00      1.00      1.00         8\n",
      "          28       1.00      1.00      1.00         8\n",
      "          29       1.00      1.00      1.00         8\n",
      "          30       1.00      1.00      1.00         8\n",
      "          31       1.00      1.00      1.00         8\n",
      "          32       1.00      1.00      1.00         8\n",
      "          33       1.00      1.00      1.00         8\n",
      "          34       1.00      1.00      1.00         8\n",
      "          35       1.00      1.00      1.00         8\n",
      "          36       1.00      1.00      1.00         8\n",
      "          37       1.00      1.00      1.00         8\n",
      "          38       1.00      1.00      1.00         8\n",
      "          39       1.00      1.00      1.00         8\n",
      "          40       1.00      1.00      1.00         8\n",
      "          41       1.00      1.00      1.00         8\n",
      "          42       1.00      1.00      1.00         8\n",
      "          43       1.00      1.00      1.00         8\n",
      "          44       1.00      1.00      1.00         8\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       1.00      1.00      1.00         8\n",
      "          47       1.00      1.00      1.00         8\n",
      "          48       1.00      1.00      1.00         8\n",
      "          49       1.00      1.00      1.00         8\n",
      "          50       1.00      1.00      1.00         8\n",
      "          51       1.00      1.00      1.00         8\n",
      "          52       1.00      1.00      1.00         8\n",
      "          53       1.00      1.00      1.00         8\n",
      "          54       1.00      1.00      1.00         8\n",
      "          55       1.00      1.00      1.00         8\n",
      "          56       1.00      1.00      1.00         8\n",
      "          57       1.00      1.00      1.00         8\n",
      "          58       1.00      1.00      1.00         8\n",
      "          59       1.00      1.00      1.00         8\n",
      "          60       1.00      1.00      1.00         8\n",
      "          61       1.00      1.00      1.00         8\n",
      "          62       1.00      1.00      1.00         8\n",
      "          63       1.00      1.00      1.00         8\n",
      "          64       1.00      1.00      1.00         8\n",
      "          65       1.00      1.00      1.00         8\n",
      "          66       1.00      1.00      1.00         8\n",
      "          67       1.00      1.00      1.00         8\n",
      "          68       1.00      1.00      1.00         8\n",
      "          69       1.00      1.00      1.00         8\n",
      "          70       1.00      1.00      1.00         8\n",
      "          71       1.00      1.00      1.00         8\n",
      "          72       1.00      1.00      1.00         8\n",
      "          73       1.00      1.00      1.00         8\n",
      "          74       1.00      1.00      1.00         8\n",
      "          75       1.00      1.00      1.00         8\n",
      "          76       1.00      1.00      1.00         8\n",
      "          77       1.00      1.00      1.00         8\n",
      "          78       1.00      1.00      1.00         8\n",
      "          79       1.00      1.00      1.00         8\n",
      "          80       1.00      1.00      1.00         8\n",
      "          81       1.00      1.00      1.00         8\n",
      "          82       1.00      1.00      1.00         8\n",
      "          83       1.00      1.00      1.00         8\n",
      "          84       1.00      1.00      1.00         8\n",
      "          85       1.00      1.00      1.00         8\n",
      "          86       1.00      1.00      1.00         8\n",
      "          87       1.00      1.00      1.00         8\n",
      "          88       1.00      1.00      1.00         8\n",
      "          89       1.00      1.00      1.00         8\n",
      "          90       1.00      1.00      1.00         8\n",
      "          91       1.00      1.00      1.00         8\n",
      "          92       1.00      1.00      1.00         8\n",
      "          93       1.00      1.00      1.00         8\n",
      "          94       1.00      1.00      1.00         8\n",
      "          95       1.00      1.00      1.00         8\n",
      "          96       1.00      1.00      1.00         8\n",
      "          97       1.00      1.00      1.00         8\n",
      "          98       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00       792\n",
      "   macro avg       1.00      1.00      1.00       792\n",
      "weighted avg       1.00      1.00      1.00       792\n",
      "\n",
      "Accuracy of SVM classifier on training set: 100.00\n"
     ]
    }
   ],
   "source": [
    "#svm training\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "\n",
    "model_svm2 = svm.SVC(gamma=0.001, C=100.)\n",
    "model_svm2.fit(X_train,y_train)\n",
    "y_pred2 = model_svm2.predict(X_train)\n",
    "\n",
    "rmse = mean_squared_error(y_train, y_pred2, squared=False)\n",
    "confusion_matrix2 = confusion_matrix(y_train, y_pred2)\n",
    "\n",
    "print(classification_report(y_train, y_pred2))\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'.format(model_svm2.score(X_train, y_train)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#create folder\n",
    "original_path = 'images'\n",
    "\n",
    "new_path = 'splited_images'\n",
    "\n",
    "os.mkdir(new_path) # create this folder\n",
    "\n",
    "train_dir = os.path.join(new_path,'train')\n",
    "valid_dir = os.path.join(new_path, 'validation')\n",
    "\n",
    "\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(valid_dir)\n",
    "\n",
    "def create_species_folder(path):\n",
    "    for specie in Y_train.unique():\n",
    "        specie_path = os.path.join(path, specie)\n",
    "        os.mkdir(specie_path)\n",
    "\n",
    "create_species_folder(train_dir)\n",
    "create_species_folder(valid_dir)\n",
    "\n",
    "def copy_image(idx, species, path):\n",
    "    for i in idx.index:\n",
    "        name = '{}.jpg'.format(idx.loc[i])\n",
    "        specie = species.loc[i]\n",
    "        specie_path = os.path.join(path, specie)\n",
    "        src = os.path.join(original_path, name)\n",
    "        dst = os.path.join(specie_path, name)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "copy_image(train_id, train_species, train_dir)\n",
    "copy_image(valid_id, valid_species, valid_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                                       shear_range = 0.5,\n",
    "                                                       horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (96, 96)\n",
    "batch_size = 32\n",
    "class_mode = 'categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 792 images belonging to 99 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = datagen.flow_from_directory(directory= train_dir, \n",
    "                                           target_size= target_size, \n",
    "                                           batch_size= batch_size, \n",
    "                                           class_mode= class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 images belonging to 99 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_set = datagen.flow_from_directory(directory= valid_dir, \n",
    "                                        target_size= target_size, \n",
    "                                        batch_size= batch_size, \n",
    "                                        class_mode= class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model\n",
    "def classifier():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(filters = 32, kernel_size = (3,3), input_shape = (96,96,3), activation = \"relu\" ),\n",
    "        keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "        keras.layers.Dense(units = 99, activation = 'softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 8s 239ms/step - loss: 4.6446 - accuracy: 0.0376 - val_loss: 4.3052 - val_accuracy: 0.0657\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 3.7215 - accuracy: 0.1771 - val_loss: 3.2630 - val_accuracy: 0.2677\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 2.4407 - accuracy: 0.4144 - val_loss: 2.5148 - val_accuracy: 0.3838\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.3768 - accuracy: 0.6439 - val_loss: 2.1998 - val_accuracy: 0.4242\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 1.0737 - accuracy: 0.7220 - val_loss: 2.2615 - val_accuracy: 0.4545\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.8560 - accuracy: 0.7427 - val_loss: 2.1768 - val_accuracy: 0.4747\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 0.4651 - accuracy: 0.8624 - val_loss: 2.1095 - val_accuracy: 0.5303\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 0.3112 - accuracy: 0.9140 - val_loss: 2.1655 - val_accuracy: 0.4646\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.2259 - accuracy: 0.9408 - val_loss: 2.0156 - val_accuracy: 0.5404\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.1997 - accuracy: 0.9418 - val_loss: 2.2092 - val_accuracy: 0.5152\n"
     ]
    }
   ],
   "source": [
    "history = clf2.fit(training_set, validation_data=valid_set, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.5101\n"
     ]
    }
   ],
   "source": [
    "print('accuracy is ', round(clf2.evaluate(valid_set, verbose =0)[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_img(model):\n",
    "    test_df = pd.DataFrame(columns= Y_train.unique())\n",
    "    for i in test_id:\n",
    "        name = '{}.jpg'.format(i)\n",
    "        test_path = os.path.join(original_path, name) \n",
    "        img = keras.preprocessing.image.load_img(test_path, target_size = target_size)\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        res = model.predict(img)\n",
    "        test_df.loc[i] = res[0]\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_img(clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Pterocarya_Stenoptera</th>\n",
       "      <th>Quercus_Hartwissiana</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Quercus_Variabilis</th>\n",
       "      <th>Magnolia_Salicifolia</th>\n",
       "      <th>Quercus_Canariensis</th>\n",
       "      <th>Quercus_Rubra</th>\n",
       "      <th>Quercus_Brantii</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>...</th>\n",
       "      <th>Quercus_Ellipsoidalis</th>\n",
       "      <th>Quercus_x_Hispanica</th>\n",
       "      <th>Quercus_Shumardii</th>\n",
       "      <th>Quercus_Rhysophylla</th>\n",
       "      <th>Castanea_Sativa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Quercus_Nigra</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Quercus_Infectoria_sub</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acer_Opalus  Pterocarya_Stenoptera  Quercus_Hartwissiana  Tilia_Tomentosa  \\\n",
       "4           0.0                    0.0                   0.0              0.0   \n",
       "7           0.0                    0.0                   0.0              0.0   \n",
       "9           0.0                    1.0                   0.0              0.0   \n",
       "12          0.0                    0.0                   0.0              0.0   \n",
       "13          0.0                    0.0                   0.0              0.0   \n",
       "\n",
       "    Quercus_Variabilis  Magnolia_Salicifolia  Quercus_Canariensis  \\\n",
       "4                  0.0                   0.0                  0.0   \n",
       "7                  0.0                   0.0                  0.0   \n",
       "9                  0.0                   0.0                  0.0   \n",
       "12                 0.0                   0.0                  0.0   \n",
       "13                 0.0                   0.0                  0.0   \n",
       "\n",
       "    Quercus_Rubra  Quercus_Brantii  Salix_Fragilis  ...  \\\n",
       "4             0.0              0.0             0.0  ...   \n",
       "7             0.0              0.0             0.0  ...   \n",
       "9             0.0              0.0             0.0  ...   \n",
       "12            0.0              0.0             0.0  ...   \n",
       "13            0.0              0.0             0.0  ...   \n",
       "\n",
       "    Quercus_Ellipsoidalis  Quercus_x_Hispanica  Quercus_Shumardii  \\\n",
       "4                     0.0                  0.0                0.0   \n",
       "7                     0.0                  0.0                0.0   \n",
       "9                     0.0                  0.0                0.0   \n",
       "12                    0.0                  0.0                0.0   \n",
       "13                    0.0                  0.0                0.0   \n",
       "\n",
       "    Quercus_Rhysophylla  Castanea_Sativa  Ulmus_Bergmanniana  Quercus_Nigra  \\\n",
       "4                   0.0              0.0                 0.0            0.0   \n",
       "7                   0.0              0.0                 0.0            0.0   \n",
       "9                   0.0              0.0                 0.0            0.0   \n",
       "12                  0.0              0.0                 0.0            0.0   \n",
       "13                  0.0              0.0                 0.0            0.0   \n",
       "\n",
       "    Salix_Intergra  Quercus_Infectoria_sub  Sorbus_Aria  \n",
       "4              0.0                     0.0          0.0  \n",
       "7              0.0                     0.0          0.0  \n",
       "9              0.0                     0.0          0.0  \n",
       "12             0.0                     0.0          0.0  \n",
       "13             1.0                     0.0          0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4       1.0\n",
       "7       1.0\n",
       "9       1.0\n",
       "12      1.0\n",
       "13      1.0\n",
       "       ... \n",
       "1576    1.0\n",
       "1577    1.0\n",
       "1579    1.0\n",
       "1580    1.0\n",
       "1583    1.0\n",
       "Length: 594, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.apply(sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
